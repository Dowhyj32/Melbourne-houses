{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('melb_data.csv')\n",
    "pd.set_option('display.max_columns', None) \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Rooms','Bathroom','Bedroom2','Landsize','Lattitude','Longtitude']\n",
    "X = df[cols]\n",
    "y = df['Price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print(f'MSE: {mean_squared_error(y_test, y_pred):.2f}')\n",
    "print(f'R^2: {r2_score(y_test, y_pred):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "cols = ['Rooms','Bathroom','Bedroom2','Landsize','Lattitude','Longtitude']\n",
    "X = df[cols]\n",
    "y = df['Price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth' : [5,10,15,20,None],\n",
    "    'min_samples_split':[2,10,20,50,100],\n",
    "    'min_samples_leaf':[1,5,10,20,30]\n",
    "}\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=dtr, param_grid=param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mejores hiperparámetros:\", grid_search.best_params_)\n",
    "print(\"Mejor R²:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Distribuciones para la búsqueda aleatoria\n",
    "param_dist = {\n",
    "    'max_depth': [5, 10, 15, 20, None],\n",
    "    'min_samples_split': randint(2, 100),\n",
    "    'min_samples_leaf': randint(1, 50)\n",
    "}\n",
    "\n",
    "# Configurar RandomizedSearch\n",
    "random_search = RandomizedSearchCV(estimator=dtr, param_distributions=param_dist, n_iter=20, cv=5, scoring='r2', random_state=1, n_jobs=-1)\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mejores hiperparámetros:\", random_search.best_params_)\n",
    "print(\"Mejor R²:\", random_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elijo los hiperparámetros obtenidos a partir de 'GridSearchCV' ya que este encontró un límite de profundidad para el árbol, mientras que con 'RandomizedSearchCV' el árbol crece sin límite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr = DecisionTreeRegressor(max_depth=20, min_samples_split=50, min_samples_leaf=10, random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = dtr.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'MSE: {mse:.2f}, R^2: {r2:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "dtr_best = DecisionTreeRegressor(max_depth=20, min_samples_leaf=12, min_samples_split=30, random_state=1)\n",
    "\n",
    "cv_scores = cross_val_score(dtr_best, X_train, y_train, cv=5, scoring='r2')\n",
    "\n",
    "print(\"R² por fold:\", cv_scores)\n",
    "print(\"R² promedio:\", np.mean(cv_scores))\n",
    "print(\"Desviación estándar del R²:\", np.std(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "dtr_best = DecisionTreeRegressor(max_depth=20, min_samples_leaf=12, min_samples_split=30, random_state=1)\n",
    "\n",
    "cv_scores = cross_val_score(dtr_best, X_train, y_train, cv=5, scoring='r2')\n",
    "\n",
    "print(\"R² por fold:\", cv_scores)\n",
    "print(\"R² promedio:\", np.mean(cv_scores))\n",
    "print(\"Desviación estándar del R²:\", np.std(cv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realizó una validación cruzada con 5 folds para evaluar la estabilidad del modelo DecisionTreeRegressor ajustado con los mejores hiperparámetros obtenidos a través de Grid Search. La validación cruzada permite medir el desempeño del modelo de forma más robusta al entrenarlo y evaluarlo en diferentes particiones del conjunto de datos, evitando depender de una única división entre train y test.\n",
    "La estabilidad del modelo queda reflejada en la baja desviación estándar, indicando que el rendimiento no varía significativamente entre las distintas particiones. Además, el R² promedio (0.6876) es consistente con el R² obtenido sobre el conjunto de test (0.72), lo que sugiere que el modelo tiene un buen equilibrio entre sesgo y varianza, sin señales evidentes de sobreajuste o subajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Búsqueda de outliers para las siguientes columnas\n",
    "\n",
    "cols_out = ['Price','Landsize']\n",
    "\n",
    "for col in cols_out:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "\n",
    "    median = df[col].median()\n",
    "    mean = df[col].mean()\n",
    "\n",
    "    IQR = Q3-Q1\n",
    "\n",
    "    llimit = Q1-1.5*Q3\n",
    "    ulimit = Q3 +1.5*Q1\n",
    "\n",
    "    df[f'Outlier_{col}'] = (df[col] < llimit) | (df[col] > ulimit)    \n",
    "    \n",
    "    print(f\"Outliers columna '{col}' {df[f'Outlier_{col}'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_outliers = df[~df['Outlier_Price']]\n",
    "df_no_outliers = df_no_outliers[~df_no_outliers['Outlier_Landsize']]\n",
    "df_no_outliers.drop('Outlier', axis=1)\n",
    "df_no_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
